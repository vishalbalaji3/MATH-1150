###############################################################
## MATH/QMGT-1150                                            ##
## R Code: Chapter 9                                         ##
##                                                           ##
## Field, A. P., Miles, J. N. V., & Field, Z. C. (2012).     ##
## Discovering Statistics Using R                            ##
##                                                           ##
## (c) 2011 Andy P. Field, Jeremy N. V. Miles & Zoe C. Field ##
###############################################################

###############################################################
###############################################################
### Set the working directory 

#setwd("H:/Personal Folders - FacStaff/thompkl1/stats")
setwd("H:/Personal Folders - Students/balajv1/My Documents/math1150_stats/t-test")

getwd()










###############################################################
###############################################################
### Load packages

library(ggplot2)
library(pastecs)
library(reshape)
library(Hmisc)
library(WRS)
library(psych)








###############################################################
###############################################################
## Create a directory to store your graphs/images.
## First, create a subfolder in stats named "images".

#imageDirectory<-"H:/Personal Folders - FacStaff/thompkl1/stats/images"
imageDirectory<-"H:/Personal Folders - Students/balajv1/My Documents/math1150_stats/t-test/images_t-test"










###############################################################
###############################################################
## Import data in long format

satisfaction <- read.csv("Employee_Satisfaction.csv", header = TRUE)













###############################################################
###############################################################
## Single Sample t-Test

###############################################################
###############################################################
## Regular hours for a person who weeks 40 hours per week over
## 4 weeks would be 160 hours.
##
## Is the average hours worked in the satisfaction data 
## statistically significantly different that 160?

t.test(satisfaction$average_monthly_hours, mu=160)







###############################################################
###############################################################
## Interpretation
##
## On average, employees worked more than 160 hours per
## month (M = 201.05, SE = 0.41), which is  
## significant, t(14999) = 100.67, p < .0001.
##
## We are 95% confident that the true average hours worked
## is between 200.25 and 201.85.







describe(satisfaction$average_monthly_hours)

###############################################################
###############################################################
## Each year, the company sets a target for average employee
## evaluation score.  Last year, the average score was 71%.
## This year, the company set a goal of 71.5%
##
## The average employee evaluation score goal is 71.5% (or .715).
##
## Are this year's resulsts statistically significantly 
## different than the goal?


t.test(satisfaction$last_evaluation_score, mu=.715)

describe(satisfaction$last_evaluation_score)

###############################################################
###############################################################
## Interpretation
##
## On average, employees score higher than 0.715 (M = .716; SE = 0.001)
## However, this difference is not  significant, t(14999) = 0.79, p = .431.
##
## Because it isn't significant, we don't do a confidence interval.









###############################################################
###############################################################
## This year's average employee evaluation score (M = 71.6%) is
## actually higher than 71.5%.
##
## Are this year's results statistically significantly 
## higher than the goal?

t.test(satisfaction$last_evaluation_score, mu=.715, alternative="greater")


###############################################################
###############################################################
## Interpretation
##
## On average, employees score higher than 0.715 (M = .716; SE = 0.001)
## However, it is not significantly higher, t(14999) = 0.79, p = .216.
##
## Not significant, so no confidence interval.









## Are this year's results statistically significantly 
## higher than 71%?  What is the interpretation?

t.test(satisfaction$last_evaluation_score, mu=.71, alternative="greater")













###############################################################
###############################################################
## Interpretation
##
## On average, employees score higher than 0.71 (M = .716; SE = 0.001),
## which is significantly higher, t(14999) = 4.365, p < .001.
##
## We are 95% confident that the true average evaluation score
## is at least 71.4%.








## What if I want a 99% confidence interval? 
## What is the interpretation?

t.test(satisfaction$last_evaluation_score, mu=.71, 
       alternative="greater", conf.level=0.99)












###############################################################
###############################################################
## Interpretation
##
## On average, employees score higher than 0.71 (M = .716; SE = 0.001),
## which is significantly higher, t(14999) = 4.365, p < .001.
##
## We are 99% confident that the true average evaluation score
## is at least 71.3%.









###############################################################
###############################################################
## 
## Your turn.
##
## When data were collected last year, the average years spent
## with the company was 3.475.
##
## Is the higher average years with the company this year 
## statistically significantly higher than last year?
##
## Include a 90% confidence interval?






t.test(satisfaction$years_spent_at_company, mu=3.475, 
       alternative="greater", conf.level=0.9)














###############################################################
###############################################################
## Interpretation
##
## On average, employee time with the company (M = 3.498; SE = 0.01),
## is significantly higher than last year's average time, 
## t(14999) = 1.946, p = .025.
##
## We are 90% confident that the true average years spent with
## the company is at least 3.483 years.

###############################################################
###############################################################
## Homework:
## The csv file '2011_Home_Sales.csv' contains data for 104
## houses across the US.  The "Sale Price" variable represents
## the sales price of the house in 2011.
##
## Assume that the average sales price for homes in those 
## neighborhoods in 2011 was $162,487.
##
## Using an alpha of 0.05, did these homes sell significantly 
## higher than the average selling price for the neighborhood?
##
## If you use an alpha of 0.01, did these homes sell significantly 
## higher than the average selling price for the neighborhood?
##
## Find and interprent a 92% confidence interval for the 2011
## average selling price for these neighborhoods.
##
## Write up your results in a Word document.

###############################################################
###############################################################

###############################################################
###############################################################
## Import data in long format
homes <- read.csv("2011_Home_Sales.csv", header = TRUE)

t.test(homes$Sale.Price, mu=162487, alternative="greater", conf.level=0.92)



###############################################################
###############################################################
## Independent Samples t-Test                                ##
###############################################################
###############################################################

###############################################################
###############################################################
## Import data in long format

satisfaction <- read.csv("Employee_Satisfaction.csv", header = TRUE)

## Remember that satisfaction had 15,000 observations.
## Let's randomly sample to get a smaller dataframe of 100.

set.seed(5)
satisfaction1 <- satisfaction[sample(nrow(satisfaction), 100), ]

###############################################################
###############################################################
## We know that the average employee satisfaction score for last
## year was 71%.  We also know that the company set a goal of 71.5%
## for this year's average employee satisfaction score.
##
## Previously, we checked to see if this year's results significantly 
## different than the goal.

t.test(satisfaction1$last_evaluation_score, mu=.715)

















###############################################################
###############################################################
## Although there is no significant difference between this year's
## average score and the goal for this year, we're also interested
## in whether employees who left the company possibly left
## because they were less satisfied with the company.
## 
## To do so, we can do an independent samples t-test (either an 
## employee left or didn't leave, so every employee will be in
## one group or the other.)
##
## We do the independent samples t-test using the same t.test
## function we used when we did the single-sample t-test, we
## just give the function different information to let it know
## we're doing an independent samples t-test.
##
## Remember that with a single-sample t-test, we're comparing
## to a population mean (or to a criteria), like we did when we
## compared the current year's average satisfaction score to the
## 71.5% (0.715) goal.  The function new it was a single sample
## because we included only one variable and the mu = .715
## argument.  
##
## We can use the "Help" window to see what arguments we need.

## We can see the variables in a dataframe using ls()

ls(satisfaction1)

## We need to check assumptions.
##
## 1. Sampling distribution is normally distributed.
## 2. Data are measured at least at the interval level.
## 3. Scores in each group come from different people (independent).
## 4. Homogeneity of Variance.

## First step is to look at our data.

###############################################################
###############################################################
## Lets look at the satisfaction level variable using
## a histogram.

hist <- ggplot(satisfaction1, aes(x = satisfaction_level))
hist + geom_histogram(color = "black", fill = "blue", 
                      binwidth=.25) + ggtitle("Satisfaction Level") + 
  theme(plot.title = element_text(color="blue", size=28, face="bold"))

## Data are negatively skewed, but it's ok. We're assuming 
## the population is normally distributed, not the sample.

###############################################################
###############################################################
## Let's save the plot.
##
## To do so, we need to create the function that allows us
## to save graphs in the image directory.

saveInImageDirectory<-function(filename){
  imageFile <- file.path(imageDirectory, filename)
  ggsave(imageFile)	
}

## Now we can save the plot.
saveInImageDirectory("Satisfaction Level Histogram.png")

###############################################################
###############################################################
## Lets look at whether employees left using a bar chart.

bar <- ggplot(satisfaction1, aes(left_company))
bar + geom_bar(fill = "red") + ggtitle("Left or Retained") + 
  theme(plot.title = element_text(color="red", size=28, face="bold"))

## Let's save the plot.
saveInImageDirectory("Left or Retained Bar Chart.png")

###############################################################
###############################################################
## Let's look at variability using a box plot.


box <- ggplot(satisfaction1, aes(left_company, satisfaction_level)) 
box + geom_boxplot(width = 0.4, fill = "white") +
  geom_jitter(width = 0.1, size = 1) +
  labs(x = "Left Company", y = "Satisfaction Level")   

## We have a problem.  R sees "left_company" as a continuous
## variable instead of a grouping variable, so we need to
## fix that.

satisfaction1[,'left_factor']<-factor(satisfaction1[,'left_company'])

## Now let's see what happens

box <- ggplot(satisfaction1, aes(left_factor, satisfaction_level)) 
box + geom_boxplot(width = 0.4, fill = "white") +
  geom_jitter(width = 0.1, size = 1) +
  labs(x = "Left Company", y = "Satisfaction Level")  

## Homogeneity of Variance is violated, but it's OK.  
## The R function is built to accommodate a violotion
## of the Homogeneity of Variance assumption using
## the "Welch approximation."

## Now that we've looked at the data and the assumptions, 
## we can do the independent t-test.
## 
## We'll store the results in a list so that we can use it later.

ind.t.test<-t.test(satisfaction1$satisfaction_level ~ satisfaction1$left_factor,
                   alternative="greater")
ind.t.test

## Remember, we'll need Standard Deviation to report our results
by(satisfaction1$satisfaction_level,satisfaction1$left_factor,mean)
by(satisfaction1$satisfaction_level,satisfaction1$left_factor,sd)

###############################################################
###############################################################
## So, what does this mean?
##
## On average, employees who later left the company (M = 0.56, SD = 0.28)
## were more likely to have a lower satisfaction score than
## employees who remained with the company (M = 0.70, SD = 0.19), which is  
## significant, t(30.876) = 2.37, p = 0.01.
##
## We are 95% confident that employees who remained with the company
## scored at least .0397 higher on the satisfaction scale.
##
## -- OR --
##
## We are 95% confident that employees who left the company
## scored at least .0397 lower on the satisfaction scale.



###############################################################
###############################################################
## Labor negotiations are always complex.  Suppose that in 2014
## the city of San Francisco was negotiating contracts with
## its transit authority supervisors.  Transity authority 
## supervisors felt that their pay should be similar to
## EMT/Firefighters, but claimed they were paid substantially 
## less.  
##
## The city of San Francisco has hired us to explore the merits
## of the claim by the transit authority supervisors.  That is,
## are transit authority supervisors paid significantly less
## than EMT/Firefighters.  
##
## Regardless of our own opinion about the merits of paying
## transit supervisors equal to EMT/Firefighters, are the
## supervisors paid significantly less than EMT/Firefighters?
##
## The data can be found in the San_Francisco_Salaries_2014.csv
## file on Course Connect.

###############################################################
###############################################################
## Import the data 
salaries <- read.csv("San_Francisco_Salaries_2014.csv", header = TRUE)

## What's in the dataframe?
ls(salaries)

## We need to check assumptions.
##
## 1. Sampling distribution is normally distributed.
## 2. Data are measured at least at the interval level.
## 3. Scores in each group come from different people (independent).
## 4. Homogeneity of Variance.

## First step is to look at our data.

###############################################################
###############################################################
## Lets look at the Total Pay & Benefits variable using
## a histogram.

hist <- ggplot(salaries, aes(x = TotalPayBenefits))
hist + geom_histogram(color = "black", fill = "purple", 
                      bins=10) + ggtitle("Total Pay & Benefits") + 
  theme(plot.title = element_text(color="purple", size=28, face="bold"))

## Data are positively skewed, but it's ok. We're assuming 
## the population is normally distributed, not the sample.

###############################################################
###############################################################
## Let's save the plot.
##

saveInImageDirectory("Total Pay & Benefits Histogram.png")


###############################################################
###############################################################
## Lets look at the occupation variable  using a bar chart.

bar <- ggplot(salaries, aes(JobTitle))
bar + geom_bar(fill = "orange") + ggtitle("EMT/Firefighter or Transit") + 
  theme(plot.title = element_text(color="orange", size=28, face="bold"))

## Let's save the plot.
saveInImageDirectory("Left or Retained Bar Chart.png")

###############################################################
###############################################################
## Let's look at variability using a box plot.

box <- ggplot(salaries, aes(JobTitle, TotalPayBenefits)) 
box + geom_boxplot(width = 0.4, fill = "white") +
  geom_jitter(width = 0.1, size = 1) +
  labs(x = "Job Title", y = "Total Pay & Benefits")  

## Homogeneity of Variance is violated, but fortunately the 
## t-test function will accommodate the violation.

## Now that we've looked at the data and the assumptions, 
## we can do the independent t-test.  Because its a labor
## negotiation, let's do a 99% confidence interval.

ind.t.test<-t.test(salaries$TotalPayBenefits ~ salaries$JobTitle,
                   alternative="greater", conf.level=0.99)
ind.t.test

## Remember, we'll need Standard Deviation to report our results
by(salaries$TotalPayBenefits,salaries$JobTitle,sd)

###############################################################
###############################################################
## So, what does this mean?
##
## On average, EMTs/Firefighters (M = $184,371.90, SD = $45,083.77)
## were paid more than Transit Authority Supervisors (M = $152,337.10, 
## SD = $32,519.13) in 2014, which is significant, t(178.25) = 5.73, 
## p < 0.0001.
##
## We are 99% confident that the pay in 2014 was at least $18,919.99 
## higher for EMTs/Firefighters. 


###############################################################
###############################################################
## Dependent samples t-test

spiders <- read.delim("SpiderWide.dat.txt", header = TRUE)

spiders$diff<-spiders$real-spiders$picture

hist <- ggplot(spiders, aes(x = diff))
hist + geom_histogram(color = "black", fill = "blue", 
                      binwidth=1) + ggtitle("Difference in Reaction") + 
  theme(plot.title = element_text(color="blue", size=28, face="bold"))

t.test(spiders$real, spiders$picture, paired = TRUE)

## Remember, we'll need Mean and Standard Deviation to report our results

mean(spiders$real)
sd(spiders$real)

mean(spiders$picture)
sd(spiders$picture)

###############################################################
###############################################################
## Interpretation
##
## On average, participants scored higher on an anxiety measure
## when presented with a real spider (M = 47, SD = 11.03) than 
## when shown a picture of a spider (M = 40, SD = 9.29), which is  
## significant, t(11) = 2.4725, p = .0.03.
##
## We are 95% confident that the true difference in anxiety scores
## is between 0.76 and 13.23.


























###############################################################
###############################################################
## Assumptions for each type of t-test
##
## Single-Sample t-test
##  
##     n >= 30 -OR- population is normally distributed
##
##
## Independent Samples t-test
##
##     Sampling distribution of differences is normally distributed
##     Data are measured at the interval level
##     Samples are independent groups
##     Homogeneity of Variance
##
##
## Dependent Sample t-test
##
##     Sampling distribution of differences is normally distributed
##     Data are measured at the interval level
##     Each pair is an independent group


























###############################################################
###############################################################
## Single Sample t-Test

###############################################################
###############################################################
## The  Southeastern Real Estate Brokerage Association has hired
## you to determine whether houses in the southeast sold
## for significantly different than the national average of $140,000
## in 2011.
##
## They provided you with a dataset of homes randomly sampled
## from across the country during 2011.
##
## You have pulled out the homes sold in the southeast to
## write a report for the association.
##
## What will you report to them?


## Dataset provided by the association
homes <- read.csv("2011_Home_Sales.csv", header = TRUE)

## Subset to use only houses from the southeast
south <- homes[which(homes[2] == "S"),]

## Determine sample size for assumption
describe(south)


## Does not meet minimum n, so plot the prices
hist <- ggplot(south, aes(x = Sale.Price))
hist + geom_histogram(color = "black", fill = "blue", 
                      binwidth=1000) + ggtitle("Southeastern Sale Prices") + 
  theme(plot.title = element_text(color="blue", size=28, face="bold"))

## Really not normally distributed, so we should carefully consider whether
## to do a t-test.  But, there are other test we could do before running the
## test which would indicate it is ok to do the test.  So, let's do it.

## Single Sample t-test
t.test(south$Sale.Price, mu=140000)





























###############################################################
###############################################################
## Write-Up
##
## Per our agreement with the Southeastern Real Estate Brokerage 
## Association, we have compared the 2011 sales prices of homes
## in the southeastern United States to the 2011 national
## average price.
##
## We decided that a single-sample t-test would be the appropriate
## test, but before we conducted the test we checked to insure
## that the test would not violate the single-sample t-test
## assumption of normality.  If the sample contained at least
## 30 homes, we could proceed without checking for normality.
## However, the data provided contained only 26 homes.  Consequently,
## we used a histogram to view the distribution of homes.  Although
## the sample is not normally distributed, the assumption is that the
## population is normally distributed, so the nonnormal sample is
## not a problem. We have chosen to proceed with the test because
## the sample size is close to 30.
##
## Our test was significant at the 5% level.  On average, sales price of
## homes in the southeast (M = $129,011.50, SD = $22,560.09) was
## signifciantly different than the national average of $140,000
## t(25) = -2.484, p = 0.02.
##
## We are 95% confident that the true southeastern sales price in
## 2011 was between $119,899.30 and $138,123.80.









## What would you have told them if they had asked you to use a 1% level 
## rather than a 5% level.


























###############################################################
###############################################################
## Write-Up Using 1% Level
##
## Per our agreement with the Southeastern Real Estate Brokerage 
## Association, we have compared the 2011 sales prices of homes
## in the southeastern United States to the 2011 national
## average price.
##
## We decided that a single-sample t-test would be the appropriate
## test, but before we conducted the test we checked to insure
## that the test would not violate the single-sample t-test
## assumption of normality.  If the sample contained at least
## 30 homes, we could proceed without checking for normality.
## However, the data provided contained only 26 homes.  Consequently,
## we used a histogram to view the distribution of homes.  Although
## the sample is not normally distributed, the assumption is that the
## population is normally distributed, so the nonnormal sample is
## not a problem. We have chosen to proceed with the test because
## the sample size is close to 30.
##
## Our test was not significant at the 1% level.  On average, sales price of
## homes in the southeast (M = $129,011.50, SD = $22,560.09) was
## not signifciantly higher than the national average of $140,000
## t(25) = -2.484, p = .0.02.



